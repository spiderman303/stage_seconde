# IA de reconnaissance de chiffres manuscrits avec PyTorch
# Version avec sauvegarde incrÃ©mentale - Compatible Python 3.13.2

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
import os
import json
from datetime import datetime

# VÃ©rifier si GPU disponible
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸ–¥ï¸ Utilisation de : {device}")

print("ğŸ¤– IA de reconnaissance de chiffres manuscrits - Version incrÃ©mentale")
print("=" * 70)

# Configuration des fichiers de sauvegarde
MODELE_FICHIER = 'modele_chiffres_pytorch.pth'
HISTORIQUE_FICHIER = 'historique_entrainement.json'
OPTIMISEUR_FICHIER = 'optimiseur_pytorch.pth'

# 1. CHARGEMENT ET PRÃ‰PARATION DES DONNÃ‰ES
print("ğŸ“š Chargement des donnÃ©es MNIST...")

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)
test_dataset = datasets.MNIST('data', train=False, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)

print(f"âœ… DonnÃ©es chargÃ©es !")
print(f"   - Images d'entraÃ®nement : {len(train_dataset)}")
print(f"   - Images de test : {len(test_dataset)}")

# 2. DÃ‰FINITION DU RÃ‰SEAU DE NEURONES (identique)
class ReseauChiffres(nn.Module):
    def __init__(self):
        super(ReseauChiffres, self).__init__()
        self.fc1 = nn.Linear(28*28, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, 10)
        self.dropout = nn.Dropout(0.2)
    
    def forward(self, x):
        x = x.view(-1, 28*28)
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = F.relu(self.fc2(x))
        x = self.dropout(x)
        x = F.log_softmax(self.fc3(x), dim=1)
        return x

# 3. FONCTIONS DE SAUVEGARDE ET CHARGEMENT
def sauvegarder_modele_complet(model, optimizer, epoch, train_losses, train_accuracies, test_accuracies):
    """Sauvegarde le modÃ¨le, l'optimiseur et l'historique d'entraÃ®nement"""
    
    # Sauvegarde du modÃ¨le
    torch.save(model.state_dict(), MODELE_FICHIER)
    
    # Sauvegarde de l'optimiseur
    torch.save(optimizer.state_dict(), OPTIMISEUR_FICHIER)
    
    # Sauvegarde de l'historique
    historique = {
        'epoch_actuelle': epoch,
        'train_losses': train_losses,
        'train_accuracies': train_accuracies,
        'test_accuracies': test_accuracies,
        'derniere_sauvegarde': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        'precision_finale': test_accuracies[-1] if test_accuracies else 0
    }
    
    with open(HISTORIQUE_FICHIER, 'w') as f:
        json.dump(historique, f, indent=2)
    
    print(f"ğŸ’¾ ModÃ¨le sauvegardÃ© (Ã‰poque {epoch}, PrÃ©cision: {test_accuracies[-1]:.2f}%)")

def charger_modele_existant(model, optimizer):
    """Charge un modÃ¨le existant s'il existe"""
    
    # Initialiser les variables par dÃ©faut
    epoch_debut = 0
    train_losses = []
    train_accuracies = []
    test_accuracies = []
    
    # VÃ©rifier si les fichiers existent
    if os.path.exists(MODELE_FICHIER) and os.path.exists(HISTORIQUE_FICHIER):
        try:
            # Charger le modÃ¨le
            model.load_state_dict(torch.load(MODELE_FICHIER, map_location=device))
            print("âœ… ModÃ¨le prÃ©cÃ©dent chargÃ© avec succÃ¨s !")
            
            # Charger l'optimiseur si disponible
            if os.path.exists(OPTIMISEUR_FICHIER):
                optimizer.load_state_dict(torch.load(OPTIMISEUR_FICHIER, map_location=device))
                print("âœ… Ã‰tat de l'optimiseur chargÃ© !")
            
            # Charger l'historique
            with open(HISTORIQUE_FICHIER, 'r') as f:
                historique = json.load(f)
            
            epoch_debut = historique.get('epoch_actuelle', 0)
            train_losses = historique.get('train_losses', [])
            train_accuracies = historique.get('train_accuracies', [])
            test_accuracies = historique.get('test_accuracies', [])
            
            print(f"ğŸ“ˆ Historique chargÃ© :")
            print(f"   - Ã‰poque prÃ©cÃ©dente : {epoch_debut}")
            print(f"   - DerniÃ¨re prÃ©cision : {historique.get('precision_finale', 0):.2f}%")
            print(f"   - DerniÃ¨re sauvegarde : {historique.get('derniere_sauvegarde', 'Inconnue')}")
            
        except Exception as e:
            print(f"âš ï¸ Erreur lors du chargement : {e}")
            print("ğŸ”„ DÃ©marrage d'un nouvel entraÃ®nement...")
            epoch_debut = 0
            train_losses = []
            train_accuracies = []
            test_accuracies = []
    else:
        print("ğŸ†• Aucun modÃ¨le prÃ©cÃ©dent trouvÃ©. DÃ©marrage d'un nouvel entraÃ®nement.")
    
    return epoch_debut, train_losses, train_accuracies, test_accuracies

# 4. CRÃ‰ATION ET CHARGEMENT DU MODÃˆLE
print("\nğŸ§  CrÃ©ation/Chargement du modÃ¨le...")

model = ReseauChiffres().to(device)
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.NLLLoss()

# Charger le modÃ¨le existant si disponible
epoch_debut, train_losses, train_accuracies, test_accuracies = charger_modele_existant(model, optimizer)

total_params = sum(p.numel() for p in model.parameters())
print(f"   - Nombre total de paramÃ¨tres : {total_params:,}")

# 5. FONCTIONS D'ENTRAÃNEMENT ET TEST (identiques)
def entrainer_une_epoque(epoch_num):
    model.train()
    total_loss = 0
    correct = 0
    total = 0
    
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)
        
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        pred = output.argmax(dim=1, keepdim=True)
        correct += pred.eq(target.view_as(pred)).sum().item()
        total += target.size(0)
        
        if batch_idx % 200 == 0:
            print(f'   Ã‰poque {epoch_num} - Batch {batch_idx:3d}/{len(train_loader)} - '
                  f'Perte: {loss.item():.4f}')
    
    avg_loss = total_loss / len(train_loader)
    accuracy = 100. * correct / total
    
    return avg_loss, accuracy

def tester():
    model.eval()
    test_loss = 0
    correct = 0
    
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += criterion(output, target).item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()
    
    accuracy = 100. * correct / len(test_dataset)
    return accuracy

# 6. ENTRAÃNEMENT PRINCIPAL AVEC SAUVEGARDE INCRÃ‰MENTALE
print(f"\nğŸ‹ï¸ EntraÃ®nement de l'IA (Ã  partir de l'Ã©poque {epoch_debut + 1})...")

# Demander le nombre d'Ã©poques Ã  ajouter
print(f"ğŸ“ Combien d'Ã©poques voulez-vous ajouter ? (RecommandÃ©: 3-5)")
try:
    nouvelles_epoques = int(input("Nombre d'Ã©poques : ") or "3")
except:
    nouvelles_epoques = 3
    print(f"âš ï¸ Valeur par dÃ©faut utilisÃ©e : {nouvelles_epoques} Ã©poques")

epochs_fin = epoch_debut + nouvelles_epoques

for epoch in range(epoch_debut + 1, epochs_fin + 1):
    print(f"\n--- Ã‰poque {epoch} ---")
    
    # EntraÃ®nement
    train_loss, train_acc = entrainer_une_epoque(epoch)
    train_losses.append(train_loss)
    train_accuracies.append(train_acc)
    
    # Test
    test_acc = tester()
    test_accuracies.append(test_acc)
    
    print(f"âœ… Ã‰poque {epoch} terminÃ©e:")
    print(f"   - PrÃ©cision entraÃ®nement: {train_acc:.2f}%")
    print(f"   - PrÃ©cision test: {test_acc:.2f}%")
    
    # Sauvegarde aprÃ¨s chaque Ã©poque
    sauvegarder_modele_complet(model, optimizer, epoch, train_losses, train_accuracies, test_accuracies)

print(f"\nğŸ‰ EntraÃ®nement terminÃ© !")
print(f"ğŸ¯ PrÃ©cision finale : {test_accuracies[-1]:.2f}%")

# 7. GRAPHIQUES D'APPRENTISSAGE COMPLETS
print("\nğŸ“ˆ CrÃ©ation des graphiques d'apprentissage...")

if len(train_accuracies) > 0:
    plt.figure(figsize=(15, 5))
    
    epochs_range = range(1, len(train_accuracies) + 1)
    
    plt.subplot(1, 3, 1)
    plt.plot(epochs_range, train_accuracies, 'bo-', label='EntraÃ®nement')
    plt.plot(epochs_range, test_accuracies, 'ro-', label='Test')
    plt.title('Ã‰volution de la prÃ©cision (Historique complet)')
    plt.xlabel('Ã‰poque')
    plt.ylabel('PrÃ©cision (%)')
    plt.legend()
    plt.grid(True)
    
    plt.subplot(1, 3, 2)
    plt.plot(epochs_range, train_losses, 'go-')
    plt.title('Ã‰volution de la perte')
    plt.xlabel('Ã‰poque')
    plt.ylabel('Perte')
    plt.grid(True)
    
    # Zoom sur les derniÃ¨res Ã©poques si il y en a beaucoup
    plt.subplot(1, 3, 3)
    if len(train_accuracies) > 10:
        derniers_10 = epochs_range[-10:]
        plt.plot(derniers_10, train_accuracies[-10:], 'bo-', label='EntraÃ®nement')
        plt.plot(derniers_10, test_accuracies[-10:], 'ro-', label='Test')
        plt.title('Ã‰volution rÃ©cente (10 derniÃ¨res Ã©poques)')
    else:
        plt.plot(epochs_range, train_accuracies, 'bo-', label='EntraÃ®nement')
        plt.plot(epochs_range, test_accuracies, 'ro-', label='Test')
        plt.title('Ã‰volution complÃ¨te')
    
    plt.xlabel('Ã‰poque')
    plt.ylabel('PrÃ©cision (%)')
    plt.legend()
    plt.grid(True)
    
    plt.tight_layout()
    plt.show()

# 8. FONCTIONS DE TEST (identiques mais adaptÃ©es)
def tester_chiffre(index):
    """Teste l'IA sur un chiffre spÃ©cifique du dataset de test"""
    if index >= len(test_dataset):
        print(f"âŒ Index trop grand ! Maximum: {len(test_dataset)-1}")
        return
    
    model.eval()
    data, true_label = test_dataset[index]
    
    with torch.no_grad():
        data_batch = data.unsqueeze(0).to(device)
        output = model(data_batch)
        prediction = output.argmax(dim=1).item()
        confidence = torch.exp(output.max()).item() * 100
    
    plt.figure(figsize=(6, 4))
    img = data.squeeze().numpy()
    plt.imshow(img, cmap='gray')
    
    color = 'green' if prediction == true_label else 'red'
    plt.title(f'Chiffre rÃ©el: {true_label}\n'
              f'PrÃ©diction IA: {prediction}\n'
              f'Confiance: {confidence:.1f}%', 
              fontsize=12, color=color)
    plt.axis('off')
    plt.show()
    
    return prediction, confidence

def predire_image_perso(chemin_image):
    """PrÃ©dit le chiffre dans une image personnalisÃ©e"""
    try:
        if not os.path.exists(chemin_image):
            print(f"âŒ Fichier non trouvÃ© : {chemin_image}")
            return None, 0
        
        image_originale = Image.open(chemin_image)
        
        if image_originale.mode != 'L':
            image_gris = image_originale.convert('L')
        else:
            image_gris = image_originale
        
        image_redimensionnee = image_gris.resize((28, 28), Image.Resampling.LANCZOS)
        image_array = np.array(image_redimensionnee)
        
        if np.mean(image_array) > 127:
            image_array = 255 - image_array
        
        image_array = image_array.astype(np.float32) / 255.0
        image_array = (image_array - 0.1307) / 0.3081
        
        image_tensor = torch.from_numpy(image_array).unsqueeze(0).unsqueeze(0)
        image_tensor = image_tensor.to(device)
        
        model.eval()
        with torch.no_grad():
            output = model(image_tensor)
            prediction = output.argmax(dim=1).item()
            confidence = torch.exp(output.max()).item() * 100
        
        plt.figure(figsize=(12, 4))
        
        plt.subplot(1, 3, 1)
        plt.imshow(image_originale, cmap='gray' if image_originale.mode == 'L' else None)
        plt.title('Image originale')
        plt.axis('off')
        
        plt.subplot(1, 3, 2)
        plt.imshow(image_array, cmap='gray')
        plt.title('Image prÃ©parÃ©e\n(comme l\'IA la voit)')
        plt.axis('off')
        
        plt.subplot(1, 3, 3)
        plt.text(0.5, 0.7, f'ğŸ¤– PrÃ©diction', ha='center', fontsize=16, transform=plt.gca().transAxes)
        plt.text(0.5, 0.5, f'Chiffre: {prediction}', ha='center', fontsize=24, fontweight='bold', 
                 transform=plt.gca().transAxes)
        plt.text(0.5, 0.3, f'Confiance: {confidence:.1f}%', ha='center', fontsize=16, 
                 transform=plt.gca().transAxes)
        plt.axis('off')
        
        plt.tight_layout()
        plt.show()
        
        print(f"âœ… PrÃ©diction terminÃ©e !")
        print(f"   ğŸ¯ Chiffre dÃ©tectÃ© : {prediction}")
        print(f"   ğŸ“Š Confiance : {confidence:.1f}%")
        
        return prediction, confidence
        
    except Exception as e:
        print(f"âŒ Erreur lors du traitement de l'image : {e}")
        return None, 0

def afficher_historique():
    """Affiche l'historique complet d'entraÃ®nement"""
    if os.path.exists(HISTORIQUE_FICHIER):
        with open(HISTORIQUE_FICHIER, 'r') as f:
            historique = json.load(f)
        
        print("\nğŸ“Š HISTORIQUE D'ENTRAÃNEMENT")
        print("=" * 40)
        print(f"ğŸ¯ PrÃ©cision actuelle : {historique.get('precision_finale', 0):.2f}%")
        print(f"ğŸ“ˆ Nombre d'Ã©poques : {historique.get('epoch_actuelle', 0)}")
        print(f"ğŸ“… DerniÃ¨re sauvegarde : {historique.get('derniere_sauvegarde', 'Inconnue')}")
        
        if len(historique.get('test_accuracies', [])) > 1:
            precisions = historique['test_accuracies']
            print(f"ğŸš€ AmÃ©lioration : +{precisions[-1] - precisions[0]:.2f}% depuis le dÃ©but")
    else:
        print("âŒ Aucun historique trouvÃ©.")

def reinitialiser_modele():
    """Remet le modÃ¨le Ã  zÃ©ro (supprime les sauvegardes)"""
    response = input("âš ï¸ ÃŠtes-vous sÃ»r de vouloir supprimer le modÃ¨le existant ? (oui/non): ")
    if response.lower() in ['oui', 'yes', 'o', 'y']:
        fichiers_a_supprimer = [MODELE_FICHIER, HISTORIQUE_FICHIER, OPTIMISEUR_FICHIER]
        for fichier in fichiers_a_supprimer:
            if os.path.exists(fichier):
                os.remove(fichier)
                print(f"ğŸ—‘ï¸ {fichier} supprimÃ©")
        print("âœ… ModÃ¨le rÃ©initialisÃ© ! Relancez le script pour un nouvel entraÃ®nement.")
    else:
        print("âŒ RÃ©initialisation annulÃ©e.")

# 9. INFORMATIONS FINALES
print("\n" + "="*70)
print("ğŸ‰ ENTRAÃNEMENT TERMINÃ‰ !")
print("="*70)

# Afficher l'historique
afficher_historique()

print("\nğŸ“‹ Commandes disponibles :")
print("   - tester_chiffre(123) : teste l'exemple nÂ°123")
print("   - predire_image_perso('image.png') : teste ton image")
print("   - afficher_historique() : voir l'historique complet")
print("   - reinitialiser_modele() : remet Ã  zÃ©ro (attention !)")

print("\nğŸ’¡ Avantages de cette version :")
print("   âœ… Sauvegarde automatique aprÃ¨s chaque Ã©poque")
print("   âœ… Reprise de l'entraÃ®nement oÃ¹ vous vous Ãªtes arrÃªtÃ©")
print("   âœ… Historique complet conservÃ©")
print("   âœ… AmÃ©lioration progressive des performances")
print("   âœ… PossibilitÃ© d'ajouter quelques Ã©poques Ã  la fois")

print(f"\nğŸ¯ Pour continuer l'entraÃ®nement, relancez simplement ce script !")