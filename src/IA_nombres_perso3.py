# IA de reconnaissance de chiffres manuscrits avec PyTorch
# Version avec sauvegarde incr√©mentale - Compatible Python 3.13.2

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
import os
import json
from datetime import datetime

# V√©rifier si GPU disponible
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"üñ•Ô∏è Utilisation de : {device}")

print("ü§ñ IA de reconnaissance de chiffres manuscrits - Version incr√©mentale")
print("=" * 70)

# Configuration des fichiers de sauvegarde
MODELE_FICHIER = 'modele_chiffres_pytorch.pth'
HISTORIQUE_FICHIER = 'historique_entrainement.json'
OPTIMISEUR_FICHIER = 'optimiseur_pytorch.pth'

# 1. CHARGEMENT ET PR√âPARATION DES DONN√âES
print("üìö Chargement des donn√©es MNIST...")

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)
test_dataset = datasets.MNIST('data', train=False, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)

print(f"‚úÖ Donn√©es charg√©es !")
print(f"   - Images d'entra√Ænement : {len(train_dataset)}")
print(f"   - Images de test : {len(test_dataset)}")

# 2. D√âFINITION DU R√âSEAU DE NEURONES (identique)
class ReseauChiffres(nn.Module):
    def __init__(self):
        super(ReseauChiffres, self).__init__()
        self.fc1 = nn.Linear(28*28, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, 10)
        self.dropout = nn.Dropout(0.2)
    
    def forward(self, x):
        x = x.view(-1, 28*28)
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = F.relu(self.fc2(x))
        x = self.dropout(x)
        x = F.log_softmax(self.fc3(x), dim=1)
        return x

# 3. FONCTIONS DE SAUVEGARDE ET CHARGEMENT
def sauvegarder_modele_complet(model, optimizer, epoch, train_losses, train_accuracies, test_accuracies):
    """Sauvegarde le mod√®le, l'optimiseur et l'historique d'entra√Ænement"""
    
    # Sauvegarde du mod√®le
    torch.save(model.state_dict(), MODELE_FICHIER)
    
    # Sauvegarde de l'optimiseur
    torch.save(optimizer.state_dict(), OPTIMISEUR_FICHIER)
    
    # Sauvegarde de l'historique
    historique = {
        'epoch_actuelle': epoch,
        'train_losses': train_losses,
        'train_accuracies': train_accuracies,
        'test_accuracies': test_accuracies,
        'derniere_sauvegarde': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        'precision_finale': test_accuracies[-1] if test_accuracies else 0
    }
    
    with open(HISTORIQUE_FICHIER, 'w') as f:
        json.dump(historique, f, indent=2)
    
    print(f"üíæ Mod√®le sauvegard√© (√âpoque {epoch}, Pr√©cision: {test_accuracies[-1]:.2f}%)")

def charger_modele_existant(model, optimizer):
    """Charge un mod√®le existant s'il existe"""
    
    # Initialiser les variables par d√©faut
    epoch_debut = 0
    train_losses = []
    train_accuracies = []
    test_accuracies = []
    
    # V√©rifier si les fichiers existent
    if os.path.exists(MODELE_FICHIER) and os.path.exists(HISTORIQUE_FICHIER):
        try:
            # Charger le mod√®le
            model.load_state_dict(torch.load(MODELE_FICHIER, map_location=device))
            print("‚úÖ Mod√®le pr√©c√©dent charg√© avec succ√®s !")
            
            # Charger l'optimiseur si disponible
            if os.path.exists(OPTIMISEUR_FICHIER):
                optimizer.load_state_dict(torch.load(OPTIMISEUR_FICHIER, map_location=device))
                print("‚úÖ √âtat de l'optimiseur charg√© !")
            
            # Charger l'historique
            with open(HISTORIQUE_FICHIER, 'r') as f:
                historique = json.load(f)
            
            epoch_debut = historique.get('epoch_actuelle', 0)
            train_losses = historique.get('train_losses', [])
            train_accuracies = historique.get('train_accuracies', [])
            test_accuracies = historique.get('test_accuracies', [])
            
            print(f"üìà Historique charg√© :")
            print(f"   - √âpoque pr√©c√©dente : {epoch_debut}")
            print(f"   - Derni√®re pr√©cision : {historique.get('precision_finale', 0):.2f}%")
            print(f"   - Derni√®re sauvegarde : {historique.get('derniere_sauvegarde', 'Inconnue')}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lors du chargement : {e}")
            print("üîÑ D√©marrage d'un nouvel entra√Ænement...")
            epoch_debut = 0
            train_losses = []
            train_accuracies = []
            test_accuracies = []
    else:
        print("üÜï Aucun mod√®le pr√©c√©dent trouv√©. D√©marrage d'un nouvel entra√Ænement.")
    
    return epoch_debut, train_losses, train_accuracies, test_accuracies

# 4. CR√âATION ET CHARGEMENT DU MOD√àLE
print("\nüß† Cr√©ation/Chargement du mod√®le...")

model = ReseauChiffres().to(device)
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.NLLLoss()

# Charger le mod√®le existant si disponible
epoch_debut, train_losses, train_accuracies, test_accuracies = charger_modele_existant(model, optimizer)

total_params = sum(p.numel() for p in model.parameters())
print(f"   - Nombre total de param√®tres : {total_params:,}")

# 5. FONCTIONS D'ENTRA√éNEMENT ET TEST (identiques)
def entrainer_une_epoque(epoch_num):
    model.train()
    total_loss = 0
    correct = 0
    total = 0
    
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)
        
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        pred = output.argmax(dim=1, keepdim=True)
        correct += pred.eq(target.view_as(pred)).sum().item()
        total += target.size(0)
        
        if batch_idx % 200 == 0:
            print(f'   √âpoque {epoch_num} - Batch {batch_idx:3d}/{len(train_loader)} - '
                  f'Perte: {loss.item():.4f}')
    
    avg_loss = total_loss / len(train_loader)
    accuracy = 100. * correct / total
    
    return avg_loss, accuracy

def tester():
    model.eval()
    test_loss = 0
    correct = 0
    
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += criterion(output, target).item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()
    
    accuracy = 100. * correct / len(test_dataset)
    return accuracy

# 6. ENTRA√éNEMENT PRINCIPAL AVEC SAUVEGARDE INCR√âMENTALE
print(f"\nüèãÔ∏è Entra√Ænement de l'IA (√† partir de l'√©poque {epoch_debut + 1})...")

# Demander le nombre d'√©poques √† ajouter
print(f"üìù Combien d'√©poques voulez-vous ajouter ? (Recommand√©: 3-5)")
try:
    nouvelles_epoques = int(input("Nombre d'√©poques : ") or "3")
except:
    nouvelles_epoques = 3
    print(f"‚ö†Ô∏è Valeur par d√©faut utilis√©e : {nouvelles_epoques} √©poques")

epochs_fin = epoch_debut + nouvelles_epoques

for epoch in range(epoch_debut + 1, epochs_fin + 1):
    print(f"\n--- √âpoque {epoch} ---")
    
    # Entra√Ænement
    train_loss, train_acc = entrainer_une_epoque(epoch)
    train_losses.append(train_loss)
    train_accuracies.append(train_acc)
    
    # Test
    test_acc = tester()
    test_accuracies.append(test_acc)
    
    print(f"‚úÖ √âpoque {epoch} termin√©e:")
    print(f"   - Pr√©cision entra√Ænement: {train_acc:.2f}%")
    print(f"   - Pr√©cision test: {test_acc:.2f}%")
    
    # Sauvegarde apr√®s chaque √©poque
    sauvegarder_modele_complet(model, optimizer, epoch, train_losses, train_accuracies, test_accuracies)

print(f"\nüéâ Entra√Ænement termin√© !")
print(f"üéØ Pr√©cision finale : {test_accuracies[-1]:.2f}%")

# 7. GRAPHIQUES D'APPRENTISSAGE COMPLETS
print("\nüìà Cr√©ation des graphiques d'apprentissage...")

if len(train_accuracies) > 0:
    plt.figure(figsize=(15, 5))
    
    epochs_range = range(1, len(train_accuracies) + 1)
    
    plt.subplot(1, 3, 1)
    plt.plot(epochs_range, train_accuracies, 'bo-', label='Entra√Ænement')
    plt.plot(epochs_range, test_accuracies, 'ro-', label='Test')
    plt.title('√âvolution de la pr√©cision (Historique complet)')
    plt.xlabel('√âpoque')
    plt.ylabel('Pr√©cision (%)')
    plt.legend()
    plt.grid(True)
    
    plt.subplot(1, 3, 2)
    plt.plot(epochs_range, train_losses, 'go-')
    plt.title('√âvolution de la perte')
    plt.xlabel('√âpoque')
    plt.ylabel('Perte')
    plt.grid(True)
    
    # Zoom sur les derni√®res √©poques si il y en a beaucoup
    plt.subplot(1, 3, 3)
    if len(train_accuracies) > 10:
        derniers_10 = epochs_range[-10:]
        plt.plot(derniers_10, train_accuracies[-10:], 'bo-', label='Entra√Ænement')
        plt.plot(derniers_10, test_accuracies[-10:], 'ro-', label='Test')
        plt.title('√âvolution r√©cente (10 derni√®res √©poques)')
    else:
        plt.plot(epochs_range, train_accuracies, 'bo-', label='Entra√Ænement')
        plt.plot(epochs_range, test_accuracies, 'ro-', label='Test')
        plt.title('√âvolution compl√®te')
    
    plt.xlabel('√âpoque')
    plt.ylabel('Pr√©cision (%)')
    plt.legend()
    plt.grid(True)
    
    plt.tight_layout()
    plt.show()

# 8. FONCTIONS DE TEST (identiques mais adapt√©es)
def tester_chiffre(index):
    """Teste l'IA sur un chiffre sp√©cifique du dataset de test"""
    if index >= len(test_dataset):
        print(f"‚ùå Index trop grand ! Maximum: {len(test_dataset)-1}")
        return
    
    model.eval()
    data, true_label = test_dataset[index]
    
    with torch.no_grad():
        data_batch = data.unsqueeze(0).to(device)
        output = model(data_batch)
        prediction = output.argmax(dim=1).item()
        confidence = torch.exp(output.max()).item() * 100
    
    plt.figure(figsize=(6, 4))
    img = data.squeeze().numpy()
    plt.imshow(img, cmap='gray')
    
    color = 'green' if prediction == true_label else 'red'
    plt.title(f'Chiffre r√©el: {true_label}\n'
              f'Pr√©diction IA: {prediction}\n'
              f'Confiance: {confidence:.1f}%', 
              fontsize=12, color=color)
    plt.axis('off')
    plt.show()
    
    return prediction, confidence

def predire_image_perso(chemin_image):
    """Pr√©dit le chiffre dans une image personnalis√©e"""
    try:
        if not os.path.exists(chemin_image):
            print(f"‚ùå Fichier non trouv√© : {chemin_image}")
            return None, 0
        
        image_originale = Image.open(chemin_image)
        
        if image_originale.mode != 'L':
            image_gris = image_originale.convert('L')
        else:
            image_gris = image_originale
        
        image_redimensionnee = image_gris.resize((28, 28), Image.Resampling.LANCZOS)
        image_array = np.array(image_redimensionnee)
        
        if np.mean(image_array) > 127:
            image_array = 255 - image_array
        
        image_array = image_array.astype(np.float32) / 255.0
        image_array = (image_array - 0.1307) / 0.3081
        
        image_tensor = torch.from_numpy(image_array).unsqueeze(0).unsqueeze(0)
        image_tensor = image_tensor.to(device)
        
        model.eval()
        with torch.no_grad():
            output = model(image_tensor)
            prediction = output.argmax(dim=1).item()
            confidence = torch.exp(output.max()).item() * 100
        
        plt.figure(figsize=(12, 4))
        
        plt.subplot(1, 3, 1)
        plt.imshow(image_originale, cmap='gray' if image_originale.mode == 'L' else None)
        plt.title('Image originale')
        plt.axis('off')
        
        plt.subplot(1, 3, 2)
        plt.imshow(image_array, cmap='gray')
        plt.title('Image pr√©par√©e\n(comme l\'IA la voit)')
        plt.axis('off')
        
        plt.subplot(1, 3, 3)
        plt.text(0.5, 0.7, f'ü§ñ Pr√©diction', ha='center', fontsize=16, transform=plt.gca().transAxes)
        plt.text(0.5, 0.5, f'Chiffre: {prediction}', ha='center', fontsize=24, fontweight='bold', 
                 transform=plt.gca().transAxes)
        plt.text(0.5, 0.3, f'Confiance: {confidence:.1f}%', ha='center', fontsize=16, 
                 transform=plt.gca().transAxes)
        plt.axis('off')
        
        plt.tight_layout()
        plt.show()
        
        print(f"‚úÖ Pr√©diction termin√©e !")
        print(f"   üéØ Chiffre d√©tect√© : {prediction}")
        print(f"   üìä Confiance : {confidence:.1f}%")
        
        return prediction, confidence
        
    except Exception as e:
        print(f"‚ùå Erreur lors du traitement de l'image : {e}")
        return None, 0

def afficher_historique():
    """Affiche l'historique complet d'entra√Ænement"""
    if os.path.exists(HISTORIQUE_FICHIER):
        with open(HISTORIQUE_FICHIER, 'r') as f:
            historique = json.load(f)
        
        print("\nüìä HISTORIQUE D'ENTRA√éNEMENT")
        print("=" * 40)
        print(f"üéØ Pr√©cision actuelle : {historique.get('precision_finale', 0):.2f}%")
        print(f"üìà Nombre d'√©poques : {historique.get('epoch_actuelle', 0)}")
        print(f"üìÖ Derni√®re sauvegarde : {historique.get('derniere_sauvegarde', 'Inconnue')}")
        
        if len(historique.get('test_accuracies', [])) > 1:
            precisions = historique['test_accuracies']
            print(f"üöÄ Am√©lioration : +{precisions[-1] - precisions[0]:.2f}% depuis le d√©but")
    else:
        print("‚ùå Aucun historique trouv√©.")

def reinitialiser_modele():
    """Remet le mod√®le √† z√©ro (supprime les sauvegardes)"""
    response = input("‚ö†Ô∏è √ätes-vous s√ªr de vouloir supprimer le mod√®le existant ? (oui/non): ")
    if response.lower() in ['oui', 'yes', 'o', 'y']:
        fichiers_a_supprimer = [MODELE_FICHIER, HISTORIQUE_FICHIER, OPTIMISEUR_FICHIER]
        for fichier in fichiers_a_supprimer:
            if os.path.exists(fichier):
                os.remove(fichier)
                print(f"üóëÔ∏è {fichier} supprim√©")
        print("‚úÖ Mod√®le r√©initialis√© ! Relancez le script pour un nouvel entra√Ænement.")
    else:
        print("‚ùå R√©initialisation annul√©e.")

# 9. INFORMATIONS FINALES
print("\n" + "="*70)
print("üéâ ENTRA√éNEMENT TERMIN√â !")
print("="*70)

# Afficher l'historique
afficher_historique()

print("\nüìã Commandes disponibles :")
print("   - tester_chiffre(123) : teste l'exemple n¬∞123")
print("   - predire_image_perso('image.png') : teste ton image")
print("   - afficher_historique() : voir l'historique complet")
print("   - reinitialiser_modele() : remet √† z√©ro (attention !)")

print("\nüí° Avantages de cette version :")
print("   ‚úÖ Sauvegarde automatique apr√®s chaque √©poque")
print("   ‚úÖ Reprise de l'entra√Ænement o√π vous vous √™tes arr√™t√©")
print("   ‚úÖ Historique complet conserv√©")
print("   ‚úÖ Am√©lioration progressive des performances")
print("   ‚úÖ Possibilit√© d'ajouter quelques √©poques √† la fois")

print(f"\nüéØ Pour continuer l'entra√Ænement, relancez simplement ce script !")