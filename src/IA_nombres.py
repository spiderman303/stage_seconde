# IA de reconnaissance de chiffres manuscrits
# Projet pour classe de seconde

import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt

print("ü§ñ Cr√©ation d'une IA pour reconna√Ætre les chiffres manuscrits")
print("=" * 60)

# 1. CHARGEMENT DES DONN√âES
print("üìö Chargement des donn√©es d'entra√Ænement...")
# MNIST = base de donn√©es avec 70 000 images de chiffres dessin√©s √† la main
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

print(f"‚úÖ Donn√©es charg√©es !")
print(f"   - Images d'entra√Ænement : {x_train.shape[0]}")
print(f"   - Images de test : {x_test.shape[0]}")
print(f"   - Taille de chaque image : {x_train.shape[1]}x{x_train.shape[2]} pixels")

# 2. VISUALISATION DE QUELQUES EXEMPLES
print("\nüñºÔ∏è Affichage de quelques exemples...")
plt.figure(figsize=(12, 6))
for i in range(10):
    plt.subplot(2, 5, i+1)
    plt.imshow(x_train[i], cmap='gray')
    plt.title(f'Chiffre: {y_train[i]}')
    plt.axis('off')
plt.suptitle('Exemples de chiffres manuscrits', fontsize=16)
plt.tight_layout()
plt.show()

# 3. PR√âPARATION DES DONN√âES
print("\nüîß Pr√©paration des donn√©es...")
# Normalisation : convertir les valeurs de 0-255 vers 0-1
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Aplatir les images 28x28 en vecteurs de 784 valeurs
x_train = x_train.reshape(x_train.shape[0], 28*28)
x_test = x_test.reshape(x_test.shape[0], 28*28)

print(f"‚úÖ Donn√©es pr√©par√©es !")
print(f"   - Forme finale des donn√©es : {x_train.shape}")

# 4. CR√âATION DU MOD√àLE D'IA
print("\nüß† Construction du r√©seau de neurones...")
model = keras.Sequential([
    # Couche d'entr√©e : 784 neurones (un par pixel)
    keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    
    # Couche cach√©e : 128 neurones
    keras.layers.Dense(64, activation='relu'),
    
    # Couche de sortie : 10 neurones (un par chiffre 0-9)
    keras.layers.Dense(10, activation='softmax')
])

# Configuration de l'apprentissage
model.compile(
    optimizer='adam',      # Algorithme d'optimisation
    loss='sparse_categorical_crossentropy',  # Fonction de perte
    metrics=['accuracy']   # Mesure de performance
)

print("‚úÖ R√©seau de neurones cr√©√© !")
print(f"   - Nombre total de param√®tres : {model.count_params():,}")

# 5. ENTRA√éNEMENT DE L'IA
print("\nüèãÔ∏è Entra√Ænement de l'IA en cours...")
print("   (Cela peut prendre quelques minutes)")

# Entra√Ænement sur 5 √©poques (5 passages sur toutes les donn√©es)
history = model.fit(
    x_train, y_train,
    epochs=5,
    batch_size=32,
    validation_split=0.1,  # 10% des donn√©es pour validation
    verbose=1
)

print("‚úÖ Entra√Ænement termin√© !")

# 6. √âVALUATION DES PERFORMANCES
print("\nüìä √âvaluation des performances...")
test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)
print(f"‚úÖ Pr√©cision sur les donn√©es de test : {test_accuracy:.2%}")

# 7. GRAPHIQUE DE L'APPRENTISSAGE
print("\nüìà Cr√©ation du graphique d'apprentissage...")
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Pr√©cision entra√Ænement')
plt.plot(history.history['val_accuracy'], label='Pr√©cision validation')
plt.title('√âvolution de la pr√©cision')
plt.xlabel('√âpoque')
plt.ylabel('Pr√©cision')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Perte entra√Ænement')
plt.plot(history.history['val_loss'], label='Perte validation')
plt.title('√âvolution de la perte')
plt.xlabel('√âpoque')
plt.ylabel('Perte')
plt.legend()

plt.tight_layout()
plt.show()

# 8. TEST SUR QUELQUES EXEMPLES
print("\nüîç Test de l'IA sur quelques exemples...")
predictions = model.predict(x_test[:10])

plt.figure(figsize=(15, 6))
for i in range(10):
    plt.subplot(2, 5, i+1)
    
    # Reformer l'image 28x28 pour l'affichage
    image = x_test[i].reshape(28, 28)
    plt.imshow(image, cmap='gray')
    
    # Pr√©diction de l'IA
    predicted_digit = np.argmax(predictions[i])
    confidence = np.max(predictions[i]) * 100
    
    # Vraie r√©ponse
    true_digit = y_test[i]
    
    # Couleur : vert si correct, rouge si incorrect
    color = 'green' if predicted_digit == true_digit else 'red'
    
    plt.title(f'Vrai: {true_digit}\nIA: {predicted_digit} ({confidence:.1f}%)', 
              color=color, fontsize=10)
    plt.axis('off')

plt.suptitle('Pr√©dictions de l\'IA (vert = correct, rouge = erreur)', fontsize=14)
plt.tight_layout()
plt.show()

# 9. FONCTION POUR TESTER UN CHIFFRE SP√âCIFIQUE
def tester_chiffre(index):
    """Teste l'IA sur un chiffre sp√©cifique"""
    image = x_test[index].reshape(28, 28)
    prediction = model.predict(x_test[index:index+1])
    predicted_digit = np.argmax(prediction)
    confidence = np.max(prediction) * 100
    true_digit = y_test[index]
    
    plt.figure(figsize=(6, 4))
    plt.imshow(image, cmap='gray')
    plt.title(f'Chiffre r√©el: {true_digit}\n'
              f'Pr√©diction IA: {predicted_digit}\n'
              f'Confiance: {confidence:.1f}%', fontsize=12)
    plt.axis('off')
    plt.show()
    
    return predicted_digit, confidence

# 10. SAUVEGARDE DU MOD√àLE
print("\nüíæ Sauvegarde du mod√®le...")
model.save('modele_chiffres.h5')
print("‚úÖ Mod√®le sauvegard√© sous 'modele_chiffres.h5'")

print("\nüéâ PROJET TERMIN√â !")
print("=" * 60)
print(f"üéØ Pr√©cision finale : {test_accuracy:.2%}")
print("üîß Pour tester un exemple : tester_chiffre(42)")
print("üìÅ Mod√®le sauvegard√© : modele_chiffres.h5")