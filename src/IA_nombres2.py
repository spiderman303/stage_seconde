# IA de reconnaissance de chiffres manuscrits avec PyTorch
# Compatible Python 3.13.2 - Projet pour classe de seconde

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import numpy as np

# V√©rifier si GPU disponible
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"üñ•Ô∏è Utilisation de : {device}")

print("ü§ñ Cr√©ation d'une IA pour reconna√Ætre les chiffres manuscrits")
print("=" * 60)

# 1. CHARGEMENT ET PR√âPARATION DES DONN√âES
print("üìö Chargement des donn√©es MNIST...")

# Transformations pour normaliser les donn√©es
transform = transforms.Compose([
    transforms.ToTensor(),  # Convertit en tensor PyTorch
    transforms.Normalize((0.1307,), (0.3081,))  # Normalisation MNIST standard
])

# T√©l√©chargement des donn√©es
train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)
test_dataset = datasets.MNIST('data', train=False, transform=transform)

# Cr√©ation des loaders pour traiter les donn√©es par petits groupes
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)

print(f"‚úÖ Donn√©es charg√©es !")
print(f"   - Images d'entra√Ænement : {len(train_dataset)}")
print(f"   - Images de test : {len(test_dataset)}")

# 2. VISUALISATION DE QUELQUES EXEMPLES
print("\nüñºÔ∏è Affichage de quelques exemples...")
plt.figure(figsize=(12, 6))

# Prendre quelques exemples du dataset
examples = []
labels = []
for i in range(10):
    img, label = train_dataset[i]
    examples.append(img)
    labels.append(label)

for i in range(10):
    plt.subplot(2, 5, i+1)
    # Convertir le tensor en numpy et retirer la dimension couleur
    img_np = examples[i].squeeze().numpy()
    plt.imshow(img_np, cmap='gray')
    plt.title(f'Chiffre: {labels[i]}')
    plt.axis('off')

plt.suptitle('Exemples de chiffres manuscrits', fontsize=16)
plt.tight_layout()
plt.show()

# 3. D√âFINITION DU R√âSEAU DE NEURONES
print("\nüß† Construction du r√©seau de neurones...")

class ReseauChiffres(nn.Module):
    def __init__(self):
        super(ReseauChiffres, self).__init__()
        # Couches fully connected (enti√®rement connect√©es)
        self.fc1 = nn.Linear(28*28, 128)  # 784 -> 128
        self.fc2 = nn.Linear(128, 64)     # 128 -> 64
        self.fc3 = nn.Linear(64, 10)      # 64 -> 10 (0-9)
        self.dropout = nn.Dropout(0.2)    # Pour √©viter le surapprentissage
    
    def forward(self, x):
        # Aplatir l'image 28x28 en vecteur de 784
        x = x.view(-1, 28*28)
        
        # Premi√®re couche + fonction d'activation ReLU
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        
        # Deuxi√®me couche + ReLU
        x = F.relu(self.fc2(x))
        x = self.dropout(x)
        
        # Couche de sortie (pas d'activation, on utilise log_softmax)
        x = F.log_softmax(self.fc3(x), dim=1)
        return x

# Cr√©ation du mod√®le
model = ReseauChiffres().to(device)
print("‚úÖ R√©seau de neurones cr√©√© !")

# Compter les param√®tres
total_params = sum(p.numel() for p in model.parameters())
print(f"   - Nombre total de param√®tres : {total_params:,}")

# 4. CONFIGURATION DE L'ENTRA√éNEMENT
print("\n‚öôÔ∏è Configuration de l'entra√Ænement...")

# Optimiseur et fonction de perte
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.NLLLoss()  # Negative Log Likelihood Loss

# Listes pour sauvegarder les m√©triques
train_losses = []
train_accuracies = []
test_accuracies = []

# 5. FONCTION D'ENTRA√éNEMENT
def entrainer_une_epoque():
    model.train()  # Mode entra√Ænement
    total_loss = 0
    correct = 0
    total = 0
    
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)
        
        # Remettre les gradients √† z√©ro
        optimizer.zero_grad()
        
        # Pr√©diction
        output = model(data)
        
        # Calcul de la perte
        loss = criterion(output, target)
        
        # R√©tropropagation
        loss.backward()
        optimizer.step()
        
        # Statistiques
        total_loss += loss.item()
        pred = output.argmax(dim=1, keepdim=True)
        correct += pred.eq(target.view_as(pred)).sum().item()
        total += target.size(0)
        
        # Affichage du progr√®s
        if batch_idx % 200 == 0:
            print(f'   Batch {batch_idx:3d}/{len(train_loader)} - '
                  f'Perte: {loss.item():.4f}')
    
    avg_loss = total_loss / len(train_loader)
    accuracy = 100. * correct / total
    
    train_losses.append(avg_loss)
    train_accuracies.append(accuracy)
    
    return avg_loss, accuracy

# 6. FONCTION DE TEST
def tester():
    model.eval()  # Mode √©valuation
    test_loss = 0
    correct = 0
    
    with torch.no_grad():  # Pas de calcul de gradients
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += criterion(output, target).item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()
    
    accuracy = 100. * correct / len(test_dataset)
    test_accuracies.append(accuracy)
    
    return accuracy

# 7. ENTRA√éNEMENT PRINCIPAL
print("\nüèãÔ∏è Entra√Ænement de l'IA en cours...")
print("   (Cela peut prendre quelques minutes)")

epochs = 5
for epoch in range(1, epochs + 1):
    print(f"\n--- √âpoque {epoch}/{epochs} ---")
    
    # Entra√Ænement
    train_loss, train_acc = entrainer_une_epoque()
    
    # Test
    test_acc = tester()
    
    print(f"‚úÖ √âpoque {epoch} termin√©e:")
    print(f"   - Pr√©cision entra√Ænement: {train_acc:.2f}%")
    print(f"   - Pr√©cision test: {test_acc:.2f}%")

print(f"\nüéâ Entra√Ænement termin√© !")
print(f"üéØ Pr√©cision finale : {test_accuracies[-1]:.2f}%")

# 8. GRAPHIQUES D'APPRENTISSAGE
print("\nüìà Cr√©ation des graphiques d'apprentissage...")
plt.figure(figsize=(15, 5))

plt.subplot(1, 3, 1)
plt.plot(range(1, epochs+1), train_accuracies, 'bo-', label='Entra√Ænement')
plt.plot(range(1, epochs+1), test_accuracies, 'ro-', label='Test')
plt.title('√âvolution de la pr√©cision')
plt.xlabel('√âpoque')
plt.ylabel('Pr√©cision (%)')
plt.legend()
plt.grid(True)

plt.subplot(1, 3, 2)
plt.plot(range(1, epochs+1), train_losses, 'go-')
plt.title('√âvolution de la perte')
plt.xlabel('√âpoque')
plt.ylabel('Perte')
plt.grid(True)

plt.subplot(1, 3, 3)
epochs_range = range(1, epochs+1)
plt.plot(epochs_range, train_accuracies, label='Entra√Ænement')
plt.plot(epochs_range, test_accuracies, label='Test')
plt.fill_between(epochs_range, train_accuracies, alpha=0.3)
plt.fill_between(epochs_range, test_accuracies, alpha=0.3)
plt.title('Comparaison pr√©cision')
plt.xlabel('√âpoque')
plt.ylabel('Pr√©cision (%)')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

# 9. TEST SUR DES EXEMPLES SP√âCIFIQUES
print("\nüîç Test de l'IA sur quelques exemples...")

# Prendre 10 exemples du dataset de test
model.eval()
examples_data = []
examples_labels = []
predictions_data = []

with torch.no_grad():
    for i in range(10):
        data, label = test_dataset[i]
        examples_data.append(data)
        examples_labels.append(label)
        
        # Pr√©diction
        data_batch = data.unsqueeze(0).to(device)  # Ajouter dimension batch
        output = model(data_batch)
        prediction = output.argmax(dim=1).item()
        confidence = torch.exp(output.max()).item() * 100
        
        predictions_data.append((prediction, confidence))

# Affichage des r√©sultats
plt.figure(figsize=(15, 6))
for i in range(10):
    plt.subplot(2, 5, i+1)
    
    # Image
    img = examples_data[i].squeeze().numpy()
    plt.imshow(img, cmap='gray')
    
    # Informations
    true_digit = examples_labels[i]
    pred_digit, confidence = predictions_data[i]
    
    # Couleur selon si c'est correct
    color = 'green' if pred_digit == true_digit else 'red'
    
    plt.title(f'Vrai: {true_digit}\nIA: {pred_digit} ({confidence:.1f}%)', 
              color=color, fontsize=10)
    plt.axis('off')

plt.suptitle('Pr√©dictions de l\'IA (vert = correct, rouge = erreur)', fontsize=14)
plt.tight_layout()
plt.show()

# 10. FONCTION POUR TESTER UN EXEMPLE SP√âCIFIQUE
def tester_chiffre(index):
    """Teste l'IA sur un chiffre sp√©cifique du dataset de test"""
    if index >= len(test_dataset):
        print(f"‚ùå Index trop grand ! Maximum: {len(test_dataset)-1}")
        return
    
    model.eval()
    data, true_label = test_dataset[index]
    
    with torch.no_grad():
        data_batch = data.unsqueeze(0).to(device)
        output = model(data_batch)
        prediction = output.argmax(dim=1).item()
        confidence = torch.exp(output.max()).item() * 100
    
    # Affichage
    plt.figure(figsize=(6, 4))
    img = data.squeeze().numpy()
    plt.imshow(img, cmap='gray')
    
    color = 'green' if prediction == true_label else 'red'
    plt.title(f'Chiffre r√©el: {true_label}\n'
              f'Pr√©diction IA: {prediction}\n'
              f'Confiance: {confidence:.1f}%', 
              fontsize=12, color=color)
    plt.axis('off')
    plt.show()
    
    return prediction, confidence

# 11. SAUVEGARDE DU MOD√àLE
print("\nüíæ Sauvegarde du mod√®le...")
torch.save(model.state_dict(), 'modele_chiffres_pytorch.pth')
print("‚úÖ Mod√®le sauvegard√© sous 'modele_chiffres_pytorch.pth'")

# 12. INFORMATIONS FINALES
print("\n" + "="*60)
print("üéâ PROJET TERMIN√â !")
print("="*60)
print(f"üéØ Pr√©cision finale : {test_accuracies[-1]:.2f}%")
print("üîß Pour tester un exemple : tester_chiffre(42)")
print("üìÅ Mod√®le sauvegard√© : modele_chiffres_pytorch.pth")
print("\nüìã Commandes utiles :")
print("   - tester_chiffre(123) : teste l'exemple n¬∞123")
print("   - model.train() : passer en mode entra√Ænement")   
print("   - model.eval() : passer en mode √©valuation")