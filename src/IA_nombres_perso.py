# IA de reconnaissance de chiffres manuscrits avec PyTorch
# Compatible Python 3.13.2 - Projet pour classe de seconde

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
import os

# VÃ©rifier si GPU disponible
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸ–¥ï¸ Utilisation de : {device}")

print("ğŸ¤– CrÃ©ation d'une IA pour reconnaÃ®tre les chiffres manuscrits")
print("=" * 60)

# 1. CHARGEMENT ET PRÃ‰PARATION DES DONNÃ‰ES
print("ğŸ“š Chargement des donnÃ©es MNIST...")

# Transformations pour normaliser les donnÃ©es
transform = transforms.Compose([
    transforms.ToTensor(),  # Convertit en tensor PyTorch
    transforms.Normalize((0.1307,), (0.3081,))  # Normalisation MNIST standard
])

# TÃ©lÃ©chargement des donnÃ©es
train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)
test_dataset = datasets.MNIST('data', train=False, transform=transform)

# CrÃ©ation des loaders pour traiter les donnÃ©es par petits groupes
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)

print(f"âœ… DonnÃ©es chargÃ©es !")
print(f"   - Images d'entraÃ®nement : {len(train_dataset)}")
print(f"   - Images de test : {len(test_dataset)}")

# 2. VISUALISATION DE QUELQUES EXEMPLES
print("\nğŸ–¼ï¸ Affichage de quelques exemples...")
plt.figure(figsize=(12, 6))

# Prendre quelques exemples du dataset
examples = []
labels = []
for i in range(10):
    img, label = train_dataset[i]
    examples.append(img)
    labels.append(label)

for i in range(10):
    plt.subplot(2, 5, i+1)
    # Convertir le tensor en numpy et retirer la dimension couleur
    img_np = examples[i].squeeze().numpy()
    plt.imshow(img_np, cmap='gray')
    plt.title(f'Chiffre: {labels[i]}')
    plt.axis('off')

plt.suptitle('Exemples de chiffres manuscrits', fontsize=16)
plt.tight_layout()
plt.show()

# 3. DÃ‰FINITION DU RÃ‰SEAU DE NEURONES
print("\nğŸ§  Construction du rÃ©seau de neurones...")

class ReseauChiffres(nn.Module):
    def __init__(self):
        super(ReseauChiffres, self).__init__()
        # Couches fully connected (entiÃ¨rement connectÃ©es)
        self.fc1 = nn.Linear(28*28, 128)  # 784 -> 128
        self.fc2 = nn.Linear(128, 64)     # 128 -> 64
        self.fc3 = nn.Linear(64, 10)      # 64 -> 10 (0-9)
        self.dropout = nn.Dropout(0.2)    # Pour Ã©viter le surapprentissage
    
    def forward(self, x):
        # Aplatir l'image 28x28 en vecteur de 784
        x = x.view(-1, 28*28)
        
        # PremiÃ¨re couche + fonction d'activation ReLU
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        
        # DeuxiÃ¨me couche + ReLU
        x = F.relu(self.fc2(x))
        x = self.dropout(x)
        
        # Couche de sortie (pas d'activation, on utilise log_softmax)
        x = F.log_softmax(self.fc3(x), dim=1)
        return x

# CrÃ©ation du modÃ¨le
model = ReseauChiffres().to(device)
print("âœ… RÃ©seau de neurones crÃ©Ã© !")

# Compter les paramÃ¨tres
total_params = sum(p.numel() for p in model.parameters())
print(f"   - Nombre total de paramÃ¨tres : {total_params:,}")

# 4. CONFIGURATION DE L'ENTRAÃNEMENT
print("\nâš™ï¸ Configuration de l'entraÃ®nement...")

# Optimiseur et fonction de perte
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.NLLLoss()  # Negative Log Likelihood Loss

# Listes pour sauvegarder les mÃ©triques
train_losses = []
train_accuracies = []
test_accuracies = []

# 5. FONCTION D'ENTRAÃNEMENT
def entrainer_une_epoque():
    model.train()  # Mode entraÃ®nement
    total_loss = 0
    correct = 0
    total = 0
    
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)
        
        # Remettre les gradients Ã  zÃ©ro
        optimizer.zero_grad()
        
        # PrÃ©diction
        output = model(data)
        
        # Calcul de la perte
        loss = criterion(output, target)
        
        # RÃ©tropropagation
        loss.backward()
        optimizer.step()
        
        # Statistiques
        total_loss += loss.item()
        pred = output.argmax(dim=1, keepdim=True)
        correct += pred.eq(target.view_as(pred)).sum().item()
        total += target.size(0)
        
        # Affichage du progrÃ¨s
        if batch_idx % 200 == 0:
            print(f'   Batch {batch_idx:3d}/{len(train_loader)} - '
                  f'Perte: {loss.item():.4f}')
    
    avg_loss = total_loss / len(train_loader)
    accuracy = 100. * correct / total
    
    train_losses.append(avg_loss)
    train_accuracies.append(accuracy)
    
    return avg_loss, accuracy

# 6. FONCTION DE TEST
def tester():
    model.eval()  # Mode Ã©valuation
    test_loss = 0
    correct = 0
    
    with torch.no_grad():  # Pas de calcul de gradients
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += criterion(output, target).item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()
    
    accuracy = 100. * correct / len(test_dataset)
    test_accuracies.append(accuracy)
    
    return accuracy

# 7. ENTRAÃNEMENT PRINCIPAL
print("\nğŸ‹ï¸ EntraÃ®nement de l'IA en cours...")
print("   (Cela peut prendre quelques minutes)")

epochs = 5
for epoch in range(1, epochs + 1):
    print(f"\n--- Ã‰poque {epoch}/{epochs} ---")
    
    # EntraÃ®nement
    train_loss, train_acc = entrainer_une_epoque()
    
    # Test
    test_acc = tester()
    
    print(f"âœ… Ã‰poque {epoch} terminÃ©e:")
    print(f"   - PrÃ©cision entraÃ®nement: {train_acc:.2f}%")
    print(f"   - PrÃ©cision test: {test_acc:.2f}%")

print(f"\nğŸ‰ EntraÃ®nement terminÃ© !")
print(f"ğŸ¯ PrÃ©cision finale : {test_accuracies[-1]:.2f}%")

# 8. GRAPHIQUES D'APPRENTISSAGE
print("\nğŸ“ˆ CrÃ©ation des graphiques d'apprentissage...")
plt.figure(figsize=(15, 5))

plt.subplot(1, 3, 1)
plt.plot(range(1, epochs+1), train_accuracies, 'bo-', label='EntraÃ®nement')
plt.plot(range(1, epochs+1), test_accuracies, 'ro-', label='Test')
plt.title('Ã‰volution de la prÃ©cision')
plt.xlabel('Ã‰poque')
plt.ylabel('PrÃ©cision (%)')
plt.legend()
plt.grid(True)

plt.subplot(1, 3, 2)
plt.plot(range(1, epochs+1), train_losses, 'go-')
plt.title('Ã‰volution de la perte')
plt.xlabel('Ã‰poque')
plt.ylabel('Perte')
plt.grid(True)

plt.subplot(1, 3, 3)
epochs_range = range(1, epochs+1)
plt.plot(epochs_range, train_accuracies, label='EntraÃ®nement')
plt.plot(epochs_range, test_accuracies, label='Test')
plt.fill_between(epochs_range, train_accuracies, alpha=0.3)
plt.fill_between(epochs_range, test_accuracies, alpha=0.3)
plt.title('Comparaison prÃ©cision')
plt.xlabel('Ã‰poque')
plt.ylabel('PrÃ©cision (%)')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

# 9. TEST SUR DES EXEMPLES SPÃ‰CIFIQUES
print("\nğŸ” Test de l'IA sur quelques exemples...")

# Prendre 10 exemples du dataset de test
model.eval()
examples_data = []
examples_labels = []
predictions_data = []

with torch.no_grad():
    for i in range(10):
        data, label = test_dataset[i]
        examples_data.append(data)
        examples_labels.append(label)
        
        # PrÃ©diction
        data_batch = data.unsqueeze(0).to(device)  # Ajouter dimension batch
        output = model(data_batch)
        prediction = output.argmax(dim=1).item()
        confidence = torch.exp(output.max()).item() * 100
        
        predictions_data.append((prediction, confidence))

# Affichage des rÃ©sultats
plt.figure(figsize=(15, 6))
for i in range(10):
    plt.subplot(2, 5, i+1)
    
    # Image
    img = examples_data[i].squeeze().numpy()
    plt.imshow(img, cmap='gray')
    
    # Informations
    true_digit = examples_labels[i]
    pred_digit, confidence = predictions_data[i]
    
    # Couleur selon si c'est correct
    color = 'green' if pred_digit == true_digit else 'red'
    
    plt.title(f'Vrai: {true_digit}\nIA: {pred_digit} ({confidence:.1f}%)', 
              color=color, fontsize=10)
    plt.axis('off')

plt.suptitle('PrÃ©dictions de l\'IA (vert = correct, rouge = erreur)', fontsize=14)
plt.tight_layout()
plt.show()

# 10. FONCTION POUR TESTER UN EXEMPLE SPÃ‰CIFIQUE
def tester_chiffre(index):
    """Teste l'IA sur un chiffre spÃ©cifique du dataset de test"""
    if index >= len(test_dataset):
        print(f"âŒ Index trop grand ! Maximum: {len(test_dataset)-1}")
        return
    
    model.eval()
    data, true_label = test_dataset[index]
    
    with torch.no_grad():
        data_batch = data.unsqueeze(0).to(device)
        output = model(data_batch)
        prediction = output.argmax(dim=1).item()
        confidence = torch.exp(output.max()).item() * 100
    
    # Affichage
    plt.figure(figsize=(6, 4))
    img = data.squeeze().numpy()
    plt.imshow(img, cmap='gray')
    
    color = 'green' if prediction == true_label else 'red'
    plt.title(f'Chiffre rÃ©el: {true_label}\n'
              f'PrÃ©diction IA: {prediction}\n'
              f'Confiance: {confidence:.1f}%', 
              fontsize=12, color=color)
    plt.axis('off')
    plt.show()
    
    return prediction, confidence

# 11. FONCTION POUR TESTER TES PROPRES IMAGES
from PIL import Image
import os

def predire_image_perso(chemin_image):
    """
    PrÃ©dit le chiffre dans une image que tu fournis
    
    Args:
        chemin_image (str): Chemin vers ton fichier image
        
    Returns:
        tuple: (chiffre_prÃ©dit, confiance_pourcentage)
    """
    try:
        # VÃ©rifier si le fichier existe
        if not os.path.exists(chemin_image):
            print(f"âŒ Fichier non trouvÃ© : {chemin_image}")
            return None, 0
        
        # Charger l'image
        image_originale = Image.open(chemin_image)
        
        # PrÃ©paration de l'image pour l'IA
        # 1. Convertir en niveaux de gris
        if image_originale.mode != 'L':
            image_gris = image_originale.convert('L')
        else:
            image_gris = image_originale
        
        # 2. Redimensionner Ã  28x28 pixels (comme MNIST)
        image_redimensionnee = image_gris.resize((28, 28), Image.Resampling.LANCZOS)
        
        # 3. Convertir en array numpy
        image_array = np.array(image_redimensionnee)
        
        # 4. Inverser les couleurs si nÃ©cessaire (MNIST = fond noir, chiffre blanc)
        # Si l'image a un fond blanc, on l'inverse
        if np.mean(image_array) > 127:
            image_array = 255 - image_array
        
        # 5. Normaliser comme pour MNIST
        image_array = image_array.astype(np.float32) / 255.0
        
        # 6. Appliquer la mÃªme normalisation que l'entraÃ®nement
        image_array = (image_array - 0.1307) / 0.3081
        
        # 7. Convertir en tensor PyTorch
        image_tensor = torch.from_numpy(image_array).unsqueeze(0).unsqueeze(0)
        image_tensor = image_tensor.to(device)
        
        # PrÃ©diction
        model.eval()
        with torch.no_grad():
            output = model(image_tensor)
            prediction = output.argmax(dim=1).item()
            confidence = torch.exp(output.max()).item() * 100
        
        # Affichage des rÃ©sultats
        plt.figure(figsize=(12, 4))
        
        # Image originale
        plt.subplot(1, 3, 1)
        plt.imshow(image_originale, cmap='gray' if image_originale.mode == 'L' else None)
        plt.title('Image originale')
        plt.axis('off')
        
        # Image prÃ©parÃ©e (comme l'IA la voit)
        plt.subplot(1, 3, 2)
        plt.imshow(image_array, cmap='gray')
        plt.title('Image prÃ©parÃ©e\n(comme l\'IA la voit)')
        plt.axis('off')
        
        # RÃ©sultat
        plt.subplot(1, 3, 3)
        plt.text(0.5, 0.7, f'ğŸ¤– PrÃ©diction', ha='center', fontsize=16, transform=plt.gca().transAxes)
        plt.text(0.5, 0.5, f'Chiffre: {prediction}', ha='center', fontsize=24, fontweight='bold', 
                 transform=plt.gca().transAxes)
        plt.text(0.5, 0.3, f'Confiance: {confidence:.1f}%', ha='center', fontsize=16, 
                 transform=plt.gca().transAxes)
        plt.axis('off')
        
        plt.tight_layout()
        plt.show()
        
        print(f"âœ… PrÃ©diction terminÃ©e !")
        print(f"   ğŸ¯ Chiffre dÃ©tectÃ© : {prediction}")
        print(f"   ğŸ“Š Confiance : {confidence:.1f}%")
        
        return prediction, confidence
        
    except Exception as e:
        print(f"âŒ Erreur lors du traitement de l'image : {e}")
        return None, 0

# 12. FONCTION POUR CRÃ‰ER UNE IMAGE DE TEST
def creer_image_test():
    """CrÃ©e une image de test simple avec un chiffre"""
    print("ğŸ¨ CrÃ©ation d'une image de test...")
    
    # CrÃ©er une image 100x100 avec un chiffre simple
    fig, ax = plt.subplots(figsize=(3, 3))
    ax.text(0.5, 0.5, '7', fontsize=60, ha='center', va='center', 
            transform=ax.transAxes, color='black')
    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    ax.axis('off')
    
    # Sauvegarder
    plt.savefig('chiffre_test.png', bbox_inches='tight', pad_inches=0.1, 
                facecolor='white', dpi=100)
    plt.show()
    
    print("âœ… Image test crÃ©Ã©e : 'chiffre_test.png'")
    return 'chiffre_test.png'

# 13. SAUVEGARDE DU MODÃˆLE
print("\nğŸ’¾ Sauvegarde du modÃ¨le...")
torch.save(model.state_dict(), 'modele_chiffres_pytorch.pth')
print("âœ… ModÃ¨le sauvegardÃ© sous 'modele_chiffres_pytorch.pth'")

# 14. TEST AVEC UNE IMAGE CRÃ‰Ã‰E
print("\nğŸ§ª Test avec une image crÃ©Ã©e...")
fichier_test = creer_image_test()
print(f"\nğŸ” Test de l'IA sur l'image crÃ©Ã©e...")
predire_image_perso(fichier_test)

# 15. INFORMATIONS FINALES
print("\n" + "="*60)
print("ğŸ‰ PROJET TERMINÃ‰ !")
print("="*60)
print(f"ğŸ¯ PrÃ©cision finale : {test_accuracies[-1]:.2f}%")
print("ğŸ“ ModÃ¨le sauvegardÃ© : modele_chiffres_pytorch.pth")

print("\nğŸ“‹ Commandes utiles :")
print("   - tester_chiffre(123) : teste l'exemple nÂ°123 du dataset")
print("   - predire_image_perso('mon_image.png') : teste ton image")
print("   - creer_image_test() : crÃ©e une image de test")
print("\nğŸ’¡ Conseils pour tes images :")
print("   - Fond clair, chiffre foncÃ© (ou inversement)")
print("   - Chiffre bien centrÃ©")
print("   - Pas trop de bruit/dÃ©tails")
print("   - Formats supportÃ©s : PNG, JPG, JPEG, BMP")

print("\nğŸ¯ Exemple d'utilisation :")
print("   predire_image_perso('mes_images/chiffre_5.png')")